The directory /home/jusun/dever120/NCVX-Neural-Structural-Optimization/results/8y3d4ovg was created.
Building structure: mbb_beam_96x32_0.5


[33mâ•”â•â•â•â•â• QP SOLVER NOTICE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
[0m[33mâ•‘  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  â•‘
[0m[33mâ•‘  the default is osqp. Users may provide their own wrapper for the QP solver.                  â•‘
[0m[33mâ•‘  To disable this notice, set opts.quadprog_info_msg = False                                   â•‘
[0m[33mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[0mâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             â•‘
Version 1.2.0                                                                                                    â•‘
Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  â•‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
Problem specifications:                                                                                          â•‘
 # of variables                     :   685308                                                                   â•‘
 # of inequality constraints        :        0                                                                   â•‘
 # of equality constraints          :        2                                                                   â•‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
[33mLimited-memory mode enabled with size = 20.                                                                     [0m â•‘
[33mNOTE: limited-memory mode is generally NOT                                                                      [0m â•‘
[33mrecommended for nonsmooth problems.                                                                             [0m â•‘
â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
     â•‘ <--- Penalty Function --> â•‘                â•‘ Total Violation â•‘ <--- Line Search ---> â•‘ <- Stationarity -> â•‘
Iter â•‘    Mu    â”‚      Value     â•‘    Objective   â•‘ Ineq â”‚    Eq    â•‘ SD â”‚ Evals â”‚     t    â•‘ Grads â”‚    Value   â•‘
â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
   0 â•‘ 1.000000 â”‚  1.29462036576 â•‘  0.99979198545 â•‘   -  â”‚ 0.224432 â•‘ -  â”‚     1 â”‚ 0.000000 â•‘     1 â”‚ 0.543725   â•‘
  20 â•‘ 0.348678 â”‚  0.08734524491 â•‘  0.13915995036 â•‘   -  â”‚ 0.034418 â•‘ S  â”‚     3 â”‚ 0.250000 â•‘     1 â”‚ 0.024072   â•‘
  40 â•‘ 0.348678 â”‚  0.05884947891 â•‘  0.12872984071 â•‘   -  â”‚ 0.012971 â•‘ S  â”‚     3 â”‚ 0.250000 â•‘     1 â”‚ 0.002949   â•‘
  60 â•‘ 0.348678 â”‚  0.05296923032 â•‘  0.12665453594 â•‘   -  â”‚ 0.008665 â•‘ S  â”‚     7 â”‚ 0.015625 â•‘     1 â”‚ 0.015575   â•‘
  80 â•‘ 0.348678 â”‚  0.05015266446 â•‘  0.12600372663 â•‘   -  â”‚ 0.006090 â•‘ S  â”‚     2 â”‚ 0.500000 â•‘     1 â”‚ 0.004812   â•‘
 100 â•‘ 0.348678 â”‚  0.04830134334 â•‘  0.12580933614 â•‘   -  â”‚ 0.004370 â•‘ S  â”‚     6 â”‚ 0.031250 â•‘     1 â”‚ 0.007017   â•‘
 120 â•‘ 0.348678 â”‚  0.04719983686 â•‘  0.12558238130 â•‘   -  â”‚ 0.003388 â•‘ S  â”‚     6 â”‚ 0.031250 â•‘     1 â”‚ 0.012533   â•‘
 140 â•‘ 0.348678 â”‚  0.04632457086 â•‘  0.12536835783 â•‘   -  â”‚ 0.002562 â•‘ S  â”‚     9 â”‚ 0.003906 â•‘     1 â”‚ 0.011910   â•‘
 160 â•‘ 0.348678 â”‚  0.04535727360 â•‘  0.12516689917 â•‘   -  â”‚ 0.001664 â•‘ S  â”‚     6 â”‚ 0.031250 â•‘     1 â”‚ 0.002826   â•‘
 180 â•‘ 0.348678 â”‚  0.04471173357 â•‘  0.12511277122 â•‘   -  â”‚ 0.001076 â•‘ S  â”‚     5 â”‚ 0.187500 â•‘     1 â”‚ 0.012462   â•‘
 200 â•‘ 0.348678 â”‚  0.04429818104 â•‘  0.12501885150 â•‘   -  â”‚ 6.41e-04 â•‘ S  â”‚     3 â”‚ 0.250000 â•‘     1 â”‚ 6.13e-05   â•‘
 220 â•‘ 0.348678 â”‚  0.04395777649 â•‘  0.12497072124 â•‘   -  â”‚ 3.27e-04 â•‘ S  â”‚     2 â”‚ 0.500000 â•‘     1 â”‚ 5.09e-04   â•‘
 240 â•‘ 0.348678 â”‚  0.04361470954 â•‘  0.12491428639 â•‘   -  â”‚ 5.85e-05 â•‘ S  â”‚     3 â”‚ 0.250000 â•‘     1 â”‚ 4.71e-04   â•‘
 260 â•‘ 0.121577 â”‚  0.01518090858 â•‘  0.12486323602 â•‘   -  â”‚ 4.49e-07 â•‘ S  â”‚     2 â”‚ 0.500000 â•‘     1 â”‚ 6.75e-06   â•‘
 280 â•‘ 0.079766 â”‚  0.00995861559 â•‘  0.12484553608 â•‘   -  â”‚ 8.05e-08 â•‘ S  â”‚     6 â”‚ 0.031250 â•‘     3 â”‚ 1.62e-06   â•‘
 300 â•‘ 0.025032 â”‚  0.00312494396 â•‘  0.12483918471 â•‘   -  â”‚ 1.40e-08 â•‘ S  â”‚     1 â”‚ 1.000000 â•‘     1 â”‚ 3.77e-06   â•‘
â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
Optimization results:                                                                                            â•‘
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   â•‘
â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
   F â•‘          â”‚                â•‘  0.12483711760 â•‘   -  â”‚ 1.41e-10 â•‘    â”‚       â”‚          â•‘       â”‚            â•‘
   B â•‘          â”‚                â•‘  0.12483671167 â•‘   -  â”‚ 6.08e-08 â•‘    â”‚       â”‚          â•‘       â”‚            â•‘
  MF â•‘          â”‚                â•‘  0.12483711760 â•‘   -  â”‚ 1.41e-10 â•‘    â”‚       â”‚          â•‘       â”‚            â•‘
â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
Iterations:              313                                                                                     â•‘
Function evaluations:    1199                                                                                    â•‘
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           â•‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  0 J: 271.91; Vf: 0.690; loss: 1.007; relGreyElems: 1.000
 20 J: 171.79; Vf: 0.646; loss: 0.721; relGreyElems: 1.000
 40 J: 191.24; Vf: 0.597; loss: 0.781; relGreyElems: 1.000
 60 J: 193.70; Vf: 0.591; loss: 0.813; relGreyElems: 1.000
 80 J: 198.35; Vf: 0.562; loss: 0.791; relGreyElems: 1.000
100 J: 193.29; Vf: 0.541; loss: 0.745; relGreyElems: 1.000
120 J: 180.67; Vf: 0.525; loss: 0.680; relGreyElems: 1.000
140 J: 173.51; Vf: 0.522; loss: 0.652; relGreyElems: 0.077
160 J: 174.07; Vf: 0.516; loss: 0.649; relGreyElems: 0.058
180 J: 171.79; Vf: 0.512; loss: 0.637; relGreyElems: 0.040
200 J: 170.79; Vf: 0.513; loss: 0.635; relGreyElems: 0.035
220 J: 173.44; Vf: 0.506; loss: 0.639; relGreyElems: 0.033
240 J: 171.56; Vf: 0.511; loss: 0.637; relGreyElems: 0.042
260 J: 173.42; Vf: 0.506; loss: 0.640; relGreyElems: 0.036
280 J: 171.42; Vf: 0.512; loss: 0.639; relGreyElems: 0.032
300 J: 171.65; Vf: 0.508; loss: 0.635; relGreyElems: 0.026
320 J: 172.11; Vf: 0.505; loss: 0.634; relGreyElems: 0.021
340 J: 170.78; Vf: 0.514; loss: 0.642; relGreyElems: 0.025
360 J: 175.91; Vf: 0.501; loss: 0.647; relGreyElems: 0.030
380 J: 171.61; Vf: 0.507; loss: 0.635; relGreyElems: 0.020
400 J: 174.11; Vf: 0.504; loss: 0.641; relGreyElems: 0.023
420 J: 173.15; Vf: 0.511; loss: 0.646; relGreyElems: 0.027
440 J: 171.58; Vf: 0.508; loss: 0.636; relGreyElems: 0.017
460 J: 172.35; Vf: 0.503; loss: 0.634; relGreyElems: 0.018
480 J: 174.36; Vf: 0.498; loss: 0.642; relGreyElems: 0.025
500 J: 179.80; Vf: 0.497; loss: 0.662; relGreyElems: 0.019
520 J: 173.38; Vf: 0.508; loss: 0.644; relGreyElems: 0.022
540 J: 170.13; Vf: 0.510; loss: 0.636; relGreyElems: 0.018
560 J: 171.23; Vf: 0.504; loss: 0.632; relGreyElems: 0.014
580 J: 174.49; Vf: 0.500; loss: 0.642; relGreyElems: 0.013
600 J: 177.91; Vf: 0.499; loss: 0.655; relGreyElems: 0.023
620 J: 174.78; Vf: 0.503; loss: 0.644; relGreyElems: 0.018
640 J: 173.29; Vf: 0.514; loss: 0.664; relGreyElems: 0.014
660 J: 175.85; Vf: 0.500; loss: 0.647; relGreyElems: 0.021
680 J: 189.94; Vf: 0.509; loss: 0.709; relGreyElems: 0.022
700 J: 177.29; Vf: 0.511; loss: 0.668; relGreyElems: 0.018
720 J: 174.27; Vf: 0.506; loss: 0.647; relGreyElems: 0.018
740 J: 174.85; Vf: 0.505; loss: 0.647; relGreyElems: 0.020
760 J: 173.72; Vf: 0.502; loss: 0.640; relGreyElems: 0.021
780 J: 175.17; Vf: 0.500; loss: 0.644; relGreyElems: 0.017
800 J: 171.03; Vf: 0.509; loss: 0.641; relGreyElems: 0.017
820 J: 179.05; Vf: 0.497; loss: 0.660; relGreyElems: 0.018
840 J: 173.31; Vf: 0.505; loss: 0.642; relGreyElems: 0.015
860 J: 177.25; Vf: 0.501; loss: 0.652; relGreyElems: 0.015
880 J: 172.51; Vf: 0.501; loss: 0.635; relGreyElems: 0.010
900 J: 175.04; Vf: 0.502; loss: 0.644; relGreyElems: 0.014
920 J: 173.73; Vf: 0.502; loss: 0.640; relGreyElems: 0.011
940 J: 171.87; Vf: 0.508; loss: 0.646; relGreyElems: 0.015
960 J: 173.12; Vf: 0.507; loss: 0.645; relGreyElems: 0.013
980 J: 171.76; Vf: 0.505; loss: 0.637; relGreyElems: 0.016
1000 J: 172.25; Vf: 0.503; loss: 0.636; relGreyElems: 0.014
1020 J: 178.98; Vf: 0.500; loss: 0.658; relGreyElems: 0.016
1040 J: 181.33; Vf: 0.504; loss: 0.670; relGreyElems: 0.012
1060 J: 174.60; Vf: 0.499; loss: 0.642; relGreyElems: 0.016
1080 J: 173.57; Vf: 0.497; loss: 0.640; relGreyElems: 0.011
1100 J: 172.32; Vf: 0.504; loss: 0.637; relGreyElems: 0.012
1120 J: 172.13; Vf: 0.506; loss: 0.641; relGreyElems: 0.010
1140 J: 174.85; Vf: 0.503; loss: 0.645; relGreyElems: 0.012
1160 J: 171.94; Vf: 0.503; loss: 0.634; relGreyElems: 0.012
1180 J: 171.47; Vf: 0.505; loss: 0.636; relGreyElems: 0.011
1200 J: 171.14; Vf: 0.504; loss: 0.633; relGreyElems: 0.010
1220 J: 172.80; Vf: 0.503; loss: 0.637; relGreyElems: 0.010
1240 J: 171.77; Vf: 0.506; loss: 0.639; relGreyElems: 0.010
1260 J: 173.15; Vf: 0.501; loss: 0.637; relGreyElems: 0.009
1280 J: 173.22; Vf: 0.503; loss: 0.639; relGreyElems: 0.009
1300 J: 173.09; Vf: 0.504; loss: 0.639; relGreyElems: 0.009
1320 J: 171.42; Vf: 0.505; loss: 0.636; relGreyElems: 0.011
1340 J: 173.85; Vf: 0.497; loss: 0.641; relGreyElems: 0.010
1360 J: 173.15; Vf: 0.503; loss: 0.639; relGreyElems: 0.010
1380 J: 174.75; Vf: 0.496; loss: 0.645; relGreyElems: 0.008
1400 J: 174.32; Vf: 0.497; loss: 0.643; relGreyElems: 0.008
1420 J: 177.37; Vf: 0.498; loss: 0.653; relGreyElems: 0.015
1440 J: 172.32; Vf: 0.502; loss: 0.634; relGreyElems: 0.007
1460 J: 172.36; Vf: 0.500; loss: 0.634; relGreyElems: 0.012
1480 J: 174.97; Vf: 0.499; loss: 0.644; relGreyElems: 0.007
1499 J: 174.88; Vf: 0.501; loss: 0.643; relGreyElems: 0.015
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/users/5/dever120/NCVX-Neural-Structural-Optimization/tasks.py", line 1127, in <module>
    cli()
  File "/users/5/dever120/.conda/envs/general/lib/python3.11/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/5/dever120/.conda/envs/general/lib/python3.11/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/users/5/dever120/.conda/envs/general/lib/python3.11/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/5/dever120/.conda/envs/general/lib/python3.11/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/5/dever120/.conda/envs/general/lib/python3.11/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/5/dever120/NCVX-Neural-Structural-Optimization/tasks.py", line 1095, in run_multi_structure_pipeline
    ds = train_all(google_problem, max_iterations)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/5/dever120/NCVX-Neural-Structural-Optimization/tasks.py", line 345, in train_all
    ds_mma = google_train.method_of_moving_asymptotes(model, max_iterations)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/5/dever120/.conda/envs/general/lib/python3.11/site-packages/neural_structural_optimization/train.py", line 150, in method_of_moving_asymptotes
    x0 = _get_variables(model.trainable_variables).astype(np.float64)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/5/dever120/.conda/envs/general/lib/python3.11/site-packages/neural_structural_optimization/train.py", line 89, in _get_variables
    return np.concatenate([
           ^^^^^^^^^^^^^^^^
  File "/users/5/dever120/.conda/envs/general/lib/python3.11/site-packages/autograd/numpy/numpy_wrapper.py", line 38, in <lambda>
    concatenate = lambda arr_list, axis=0 : concatenate_args(axis, *arr_list)
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/5/dever120/.conda/envs/general/lib/python3.11/site-packages/autograd/tracer.py", line 48, in f_wrapped
    return f_raw(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/users/5/dever120/.conda/envs/general/lib/python3.11/site-packages/autograd/numpy/numpy_wrapper.py", line 37, in concatenate_args
    return _np.concatenate(args, axis).view(ndarray)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: need at least one array to concatenate
